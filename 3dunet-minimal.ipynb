{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from datasets.hdf5 import get_train_loaders\n",
    "from unet3d.config import load_config\n",
    "from unet3d.losses import get_loss_criterion\n",
    "from unet3d.metrics import get_evaluation_metric\n",
    "from unet3d.model import get_model\n",
    "from unet3d.trainer import UNet3DTrainer\n",
    "from unet3d.utils import get_logger\n",
    "from unet3d.utils import get_number_of_learnable_parameters\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-22 12:35:23,174 [MainThread] INFO UNet3DTrainer - {'manual_seed': 0, 'model': {'name': 'UNet3D', 'in_channels': 1, 'out_channels': 2, 'layer_order': 'crg', 'f_maps': 32, 'num_groups': 8, 'final_sigmoid': False}, 'trainer': {'checkpoint_dir': '3dunet', 'resume': None, 'validate_after_iters': 20, 'log_after_iters': 20, 'epochs': 50, 'iters': 100000, 'eval_score_higher_is_better': True}, 'optimizer': {'learning_rate': 0.0002, 'weight_decay': 0.0001}, 'loss': {'name': 'CrossEntropyLoss', 'loss_weight': None, 'ignore_index': None}, 'eval_metric': {'name': 'MeanIoU', 'ignore_index': None}, 'lr_scheduler': {'name': 'MultiStepLR', 'milestones': [10, 30, 60], 'gamma': 0.2}, 'loaders': {'train_patch': [32, 64, 64], 'train_stride': [8, 16, 16], 'val_patch': [32, 64, 64], 'val_stride': [32, 64, 64], 'raw_internal_path': 'raw', 'label_internal_path': 'label', 'train_path': ['h5_fractals/0.h5', 'h5_fractals/1.h5', 'h5_fractals/2.h5', 'h5_fractals/3.h5'], 'val_path': ['h5_fractals/4.h5'], 'num_workers': 8, 'transformer': {'train': {'raw': [{'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 3}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 0}, {'name': 'ToTensor', 'expand_dims': False, 'dtype': 'long'}]}, 'test': {'raw': [{'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'ToTensor', 'expand_dims': False, 'dtype': 'long'}]}}}, 'device': device(type='cuda', index=0)}\n",
      "2019-07-22 12:35:23,174 [MainThread] INFO UNet3DTrainer - {'manual_seed': 0, 'model': {'name': 'UNet3D', 'in_channels': 1, 'out_channels': 2, 'layer_order': 'crg', 'f_maps': 32, 'num_groups': 8, 'final_sigmoid': False}, 'trainer': {'checkpoint_dir': '3dunet', 'resume': None, 'validate_after_iters': 20, 'log_after_iters': 20, 'epochs': 50, 'iters': 100000, 'eval_score_higher_is_better': True}, 'optimizer': {'learning_rate': 0.0002, 'weight_decay': 0.0001}, 'loss': {'name': 'CrossEntropyLoss', 'loss_weight': None, 'ignore_index': None}, 'eval_metric': {'name': 'MeanIoU', 'ignore_index': None}, 'lr_scheduler': {'name': 'MultiStepLR', 'milestones': [10, 30, 60], 'gamma': 0.2}, 'loaders': {'train_patch': [32, 64, 64], 'train_stride': [8, 16, 16], 'val_patch': [32, 64, 64], 'val_stride': [32, 64, 64], 'raw_internal_path': 'raw', 'label_internal_path': 'label', 'train_path': ['h5_fractals/0.h5', 'h5_fractals/1.h5', 'h5_fractals/2.h5', 'h5_fractals/3.h5'], 'val_path': ['h5_fractals/4.h5'], 'num_workers': 8, 'transformer': {'train': {'raw': [{'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 3}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 0}, {'name': 'ToTensor', 'expand_dims': False, 'dtype': 'long'}]}, 'test': {'raw': [{'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'ToTensor', 'expand_dims': False, 'dtype': 'long'}]}}}, 'device': device(type='cuda', index=0)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gheimber/software/anaconda3/envs/dev/lib/python3.6/site-packages/ipykernel_launcher.py:15: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# set config and device parameters\n",
    "\n",
    "logger = get_logger('UNet3DTrainer')\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEFAULT_DEVICE = 'cuda:0'\n",
    "else:\n",
    "    DEFAULT_DEVICE = 'cpu'\n",
    "\n",
    "# config file\n",
    "config_file = 'resources/train_config_ce.yaml'\n",
    "#config_file = 'resources/train_config_dice.yaml'\n",
    "\n",
    "config = yaml.load(open(config_file, 'r'))\n",
    "# Get a device to train on\n",
    "device = config.get('device', DEFAULT_DEVICE)\n",
    "config['device'] = torch.device(device)\n",
    "\n",
    "logger.info(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_trainer(config, model, optimizer, lr_scheduler, loss_criterion, eval_criterion, loaders, logger):\n",
    "    assert 'trainer' in config, 'Could not find trainer configuration'\n",
    "    trainer_config = config['trainer']\n",
    "\n",
    "    resume = trainer_config.get('resume', None)\n",
    "    pre_trained = trainer_config.get('pre_trained', None)\n",
    "\n",
    "    return UNet3DTrainer(model, optimizer, lr_scheduler, loss_criterion, eval_criterion,\n",
    "                         config['device'], loaders, trainer_config['checkpoint_dir'],\n",
    "                         max_num_epochs=trainer_config['epochs'],\n",
    "                         max_num_iterations=trainer_config['iters'],\n",
    "                         validate_after_iters=trainer_config['validate_after_iters'],\n",
    "                         log_after_iters=trainer_config['log_after_iters'],\n",
    "                         eval_score_higher_is_better=trainer_config['eval_score_higher_is_better'],\n",
    "                         logger=logger)\n",
    "\n",
    "\n",
    "def _create_optimizer(config, model):\n",
    "    assert 'optimizer' in config, 'Cannot find optimizer configuration'\n",
    "    optimizer_config = config['optimizer']\n",
    "    learning_rate = optimizer_config['learning_rate']\n",
    "    weight_decay = optimizer_config['weight_decay']\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def _create_lr_scheduler(config, optimizer):\n",
    "    lr_config = config.get('lr_scheduler', None)\n",
    "    if lr_config is None:\n",
    "        # use ReduceLROnPlateau as a default scheduler\n",
    "        return ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=20, verbose=True)\n",
    "    else:\n",
    "        class_name = lr_config.pop('name')\n",
    "        m = importlib.import_module('torch.optim.lr_scheduler')\n",
    "        clazz = getattr(m, class_name)\n",
    "        # add optimizer to the config\n",
    "        lr_config['optimizer'] = optimizer\n",
    "        return clazz(**lr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-22 12:35:23,480 [MainThread] INFO UNet3DTrainer - Seed the RNG for all devices with 0\n",
      "2019-07-22 12:35:23,480 [MainThread] INFO UNet3DTrainer - Seed the RNG for all devices with 0\n",
      "2019-07-22 12:35:23,514 [MainThread] INFO UNet3DTrainer - Sending the model to 'cuda:0'\n",
      "2019-07-22 12:35:23,514 [MainThread] INFO UNet3DTrainer - Sending the model to 'cuda:0'\n",
      "2019-07-22 12:35:23,523 [MainThread] INFO UNet3DTrainer - Number of learnable params 4080914\n",
      "2019-07-22 12:35:23,523 [MainThread] INFO UNet3DTrainer - Number of learnable params 4080914\n",
      "2019-07-22 12:35:23,524 [MainThread] INFO HDF5Dataset - Creating training and validation set loaders...\n",
      "2019-07-22 12:35:23,524 [MainThread] INFO HDF5Dataset - Creating training and validation set loaders...\n",
      "2019-07-22 12:35:23,525 [MainThread] INFO HDF5Dataset - Slice builder class: SliceBuilder\n",
      "2019-07-22 12:35:23,525 [MainThread] INFO HDF5Dataset - Slice builder class: SliceBuilder\n",
      "2019-07-22 12:35:23,526 [MainThread] INFO HDF5Dataset - Loading training set from: h5_fractals/0.h5...\n",
      "2019-07-22 12:35:23,526 [MainThread] INFO HDF5Dataset - Loading training set from: h5_fractals/0.h5...\n",
      "2019-07-22 12:35:23,687 [MainThread] INFO HDF5Dataset - Loading training set from: h5_fractals/1.h5...\n",
      "2019-07-22 12:35:23,687 [MainThread] INFO HDF5Dataset - Loading training set from: h5_fractals/1.h5...\n",
      "2019-07-22 12:35:23,804 [MainThread] INFO HDF5Dataset - Loading training set from: h5_fractals/2.h5...\n",
      "2019-07-22 12:35:23,804 [MainThread] INFO HDF5Dataset - Loading training set from: h5_fractals/2.h5...\n",
      "2019-07-22 12:35:23,933 [MainThread] INFO HDF5Dataset - Loading training set from: h5_fractals/3.h5...\n",
      "2019-07-22 12:35:23,933 [MainThread] INFO HDF5Dataset - Loading training set from: h5_fractals/3.h5...\n",
      "2019-07-22 12:35:24,048 [MainThread] INFO HDF5Dataset - Loading validation set from: h5_fractals/4.h5...\n",
      "2019-07-22 12:35:24,048 [MainThread] INFO HDF5Dataset - Loading validation set from: h5_fractals/4.h5...\n",
      "2019-07-22 12:35:24,164 [MainThread] INFO HDF5Dataset - Number of workers for train/val datasets: 8\n",
      "2019-07-22 12:35:24,164 [MainThread] INFO HDF5Dataset - Number of workers for train/val datasets: 8\n",
      "2019-07-22 12:35:24,167 [MainThread] INFO UNet3DTrainer - UNet3D(\n",
      "  (encoders): ModuleList(\n",
      "    (0): Encoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (final_activation): Softmax()\n",
      ")\n",
      "2019-07-22 12:35:24,167 [MainThread] INFO UNet3DTrainer - UNet3D(\n",
      "  (encoders): ModuleList(\n",
      "    (0): Encoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (final_activation): Softmax()\n",
      ")\n",
      "2019-07-22 12:35:24,169 [MainThread] INFO UNet3DTrainer - eval_score_higher_is_better: True\n",
      "2019-07-22 12:35:24,169 [MainThread] INFO UNet3DTrainer - eval_score_higher_is_better: True\n",
      "2019-07-22 12:35:27,019 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-22 12:35:27,019 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "2019-07-22 12:35:27,619 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.3616635203361511. Evaluation score: nan\n",
      "2019-07-22 12:35:27,619 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.3616635203361511. Evaluation score: nan\n",
      "2019-07-22 12:35:27,623 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-22 12:35:27,623 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-22 12:35:27,900 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.2681346647441387. Evaluation score: 0.4999656677246094\n",
      "2019-07-22 12:35:27,900 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.2681346647441387. Evaluation score: 0.4999656677246094\n",
      "2019-07-22 12:35:27,903 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "2019-07-22 12:35:27,903 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "2019-07-22 12:35:31,140 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-22 12:35:31,140 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "2019-07-22 12:35:31,719 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.3431519716978073. Evaluation score: nan\n",
      "2019-07-22 12:35:31,719 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.3431519716978073. Evaluation score: nan\n",
      "2019-07-22 12:35:31,723 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-22 12:35:31,723 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-22 12:35:31,983 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.16952923461794853. Evaluation score: nan\n",
      "2019-07-22 12:35:31,983 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.16952923461794853. Evaluation score: nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "2019-07-22 12:35:31,985 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "2019-07-22 12:35:31,985 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "2019-07-22 12:35:35,195 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-22 12:35:35,195 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "2019-07-22 12:35:35,794 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.3352210484445095. Evaluation score: nan\n",
      "2019-07-22 12:35:35,794 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.3352210484445095. Evaluation score: nan\n",
      "2019-07-22 12:35:35,798 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-22 12:35:35,798 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-22 12:35:36,063 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.1289094536875685. Evaluation score: nan\n",
      "2019-07-22 12:35:36,063 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.1289094536875685. Evaluation score: nan\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "2019-07-22 12:35:36,065 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "2019-07-22 12:35:36,065 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "Warning: NaN or Inf found in input tensor.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0f77c90e4d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                           logger=logger)\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/lung/pytorch-3dunet/unet3d/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mshould_terminate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_terminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lung/pytorch-3dunet/unet3d/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m#    f'Training iteration {self.num_iterations}. Batch {i}. Epoch [{self.num_epoch}/{self.max_num_epochs - 1}]')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lung/pytorch-3dunet/unet3d/trainer.py\u001b[0m in \u001b[0;36m_split_training_batch\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    252\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_move_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lung/pytorch-3dunet/unet3d/trainer.py\u001b[0m in \u001b[0;36m_move_to_device\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_move_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_move_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lung/pytorch-3dunet/unet3d/trainer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_move_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_move_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lung/pytorch-3dunet/unet3d/trainer.py\u001b[0m in \u001b[0;36m_move_to_device\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and log experiment configuration\n",
    "manual_seed = config.get('manual_seed', None)\n",
    "if manual_seed is not None:\n",
    "    logger.info(f'Seed the RNG for all devices with {manual_seed}')\n",
    "    torch.manual_seed(manual_seed)\n",
    "    # see https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Create the model\n",
    "model = get_model(config)\n",
    "\n",
    "# put the model on GPUs (if available)\n",
    "#if torch.cuda.is_available():\n",
    "logger.info(f\"Sending the model to '{config['device']}'\")\n",
    "model = model.to(config['device'])\n",
    "                \n",
    "# Log the number of learnable parameters\n",
    "logger.info(f'Number of learnable params {get_number_of_learnable_parameters(model)}')\n",
    "\n",
    "# Create loss criterion\n",
    "loss_criterion = get_loss_criterion(config)\n",
    "# Create evaluation metric\n",
    "eval_criterion = get_evaluation_metric(config)\n",
    "\n",
    "# Create data loaders\n",
    "loaders = get_train_loaders(config)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = _create_optimizer(config, model)\n",
    "\n",
    "# Create learning rate adjustment strategy\n",
    "lr_scheduler = _create_lr_scheduler(config, optimizer)\n",
    "\n",
    "# Create model trainer\n",
    "trainer = _create_trainer(config, model=model, optimizer=optimizer, lr_scheduler=lr_scheduler,\n",
    "                          loss_criterion=loss_criterion, eval_criterion=eval_criterion, loaders=loaders,\n",
    "                          logger=logger)\n",
    "# Start training\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
