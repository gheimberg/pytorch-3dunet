{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from datasets.hdf5 import get_train_loaders\n",
    "from unet3d.config import load_config\n",
    "from unet3d.losses import get_loss_criterion\n",
    "from unet3d.metrics import get_evaluation_metric\n",
    "from unet3d.model import get_model\n",
    "from unet3d.trainer import UNet3DTrainer\n",
    "from unet3d.utils import get_logger\n",
    "from unet3d.utils import get_number_of_learnable_parameters\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-12 09:54:02,936 [MainThread] INFO UNet3DTrainer - {'manual_seed': 0, 'model': {'name': 'UNet3D', 'in_channels': 1, 'out_channels': 1, 'layer_order': 'crg', 'f_maps': 32, 'num_groups': 8, 'final_sigmoid': True}, 'trainer': {'checkpoint_dir': '3dunet', 'resume': None, 'validate_after_iters': 20, 'log_after_iters': 20, 'epochs': 50, 'iters': 100000, 'eval_score_higher_is_better': True}, 'optimizer': {'learning_rate': 0.0002, 'weight_decay': 0.0001}, 'loss': {'name': 'DiceLoss', 'loss_weight': None, 'ignore_index': None}, 'eval_metric': {'name': 'MeanIoU', 'ignore_index': None}, 'lr_scheduler': {'name': 'MultiStepLR', 'milestones': [10, 30, 60], 'gamma': 0.2}, 'loaders': {'train_patch': [32, 64, 64], 'train_stride': [8, 16, 16], 'val_patch': [32, 64, 64], 'val_stride': [32, 64, 64], 'raw_internal_path': 'raw', 'label_internal_path': 'label', 'train_path': ['../suki_fractals/suki_files/h5/0.h5', '../suki_fractals/suki_files/h5/1.h5', '../suki_fractals/suki_files/h5/2.h5', '../suki_fractals/suki_files/h5/3.h5'], 'val_path': ['../suki_fractals/suki_files/h5/4.h5'], 'num_workers': 8, 'transformer': {'train': {'raw': [{'name': 'Normalize'}, {'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 3}, {'name': 'RandomContrast'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 0}, {'name': 'ToTensor', 'expand_dims': True, 'dtype': 'long'}]}, 'test': {'raw': [{'name': 'Normalize'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'ToTensor', 'expand_dims': True, 'dtype': 'long'}]}}}, 'device': device(type='cpu')}\n",
      "2019-07-12 09:54:02,936 [MainThread] INFO UNet3DTrainer - {'manual_seed': 0, 'model': {'name': 'UNet3D', 'in_channels': 1, 'out_channels': 1, 'layer_order': 'crg', 'f_maps': 32, 'num_groups': 8, 'final_sigmoid': True}, 'trainer': {'checkpoint_dir': '3dunet', 'resume': None, 'validate_after_iters': 20, 'log_after_iters': 20, 'epochs': 50, 'iters': 100000, 'eval_score_higher_is_better': True}, 'optimizer': {'learning_rate': 0.0002, 'weight_decay': 0.0001}, 'loss': {'name': 'DiceLoss', 'loss_weight': None, 'ignore_index': None}, 'eval_metric': {'name': 'MeanIoU', 'ignore_index': None}, 'lr_scheduler': {'name': 'MultiStepLR', 'milestones': [10, 30, 60], 'gamma': 0.2}, 'loaders': {'train_patch': [32, 64, 64], 'train_stride': [8, 16, 16], 'val_patch': [32, 64, 64], 'val_stride': [32, 64, 64], 'raw_internal_path': 'raw', 'label_internal_path': 'label', 'train_path': ['../suki_fractals/suki_files/h5/0.h5', '../suki_fractals/suki_files/h5/1.h5', '../suki_fractals/suki_files/h5/2.h5', '../suki_fractals/suki_files/h5/3.h5'], 'val_path': ['../suki_fractals/suki_files/h5/4.h5'], 'num_workers': 8, 'transformer': {'train': {'raw': [{'name': 'Normalize'}, {'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 3}, {'name': 'RandomContrast'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 0}, {'name': 'ToTensor', 'expand_dims': True, 'dtype': 'long'}]}, 'test': {'raw': [{'name': 'Normalize'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'ToTensor', 'expand_dims': True, 'dtype': 'long'}]}}}, 'device': device(type='cpu')}\n",
      "2019-07-12 09:54:02,936 [MainThread] INFO UNet3DTrainer - {'manual_seed': 0, 'model': {'name': 'UNet3D', 'in_channels': 1, 'out_channels': 1, 'layer_order': 'crg', 'f_maps': 32, 'num_groups': 8, 'final_sigmoid': True}, 'trainer': {'checkpoint_dir': '3dunet', 'resume': None, 'validate_after_iters': 20, 'log_after_iters': 20, 'epochs': 50, 'iters': 100000, 'eval_score_higher_is_better': True}, 'optimizer': {'learning_rate': 0.0002, 'weight_decay': 0.0001}, 'loss': {'name': 'DiceLoss', 'loss_weight': None, 'ignore_index': None}, 'eval_metric': {'name': 'MeanIoU', 'ignore_index': None}, 'lr_scheduler': {'name': 'MultiStepLR', 'milestones': [10, 30, 60], 'gamma': 0.2}, 'loaders': {'train_patch': [32, 64, 64], 'train_stride': [8, 16, 16], 'val_patch': [32, 64, 64], 'val_stride': [32, 64, 64], 'raw_internal_path': 'raw', 'label_internal_path': 'label', 'train_path': ['../suki_fractals/suki_files/h5/0.h5', '../suki_fractals/suki_files/h5/1.h5', '../suki_fractals/suki_files/h5/2.h5', '../suki_fractals/suki_files/h5/3.h5'], 'val_path': ['../suki_fractals/suki_files/h5/4.h5'], 'num_workers': 8, 'transformer': {'train': {'raw': [{'name': 'Normalize'}, {'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 3}, {'name': 'RandomContrast'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'RandomFlip'}, {'name': 'RandomRotate90'}, {'name': 'RandomRotate', 'axes': [[2, 1]], 'angle_spectrum': 15, 'mode': 'reflect'}, {'name': 'ElasticDeformation', 'spline_order': 0}, {'name': 'ToTensor', 'expand_dims': True, 'dtype': 'long'}]}, 'test': {'raw': [{'name': 'Normalize'}, {'name': 'ToTensor', 'expand_dims': True}], 'label': [{'name': 'ToTensor', 'expand_dims': True, 'dtype': 'long'}]}}}, 'device': device(type='cpu')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/lung/lib/python3.7/site-packages/ipykernel_launcher.py:15: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# set config and device parameters\n",
    "\n",
    "logger = get_logger('UNet3DTrainer')\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEFAULT_DEVICE = 'cuda:0'\n",
    "else:\n",
    "    DEFAULT_DEVICE = 'cpu'\n",
    "\n",
    "# config file\n",
    "#config_file = 'resources/train_config_ce.yaml'\n",
    "config_file = 'resources/train_config_dice.yaml'\n",
    "\n",
    "config = yaml.load(open(config_file, 'r'))\n",
    "# Get a device to train on\n",
    "device = config.get('device', DEFAULT_DEVICE)\n",
    "config['device'] = torch.device(device)\n",
    "\n",
    "logger.info(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_trainer(config, model, optimizer, lr_scheduler, loss_criterion, eval_criterion, loaders, logger):\n",
    "    assert 'trainer' in config, 'Could not find trainer configuration'\n",
    "    trainer_config = config['trainer']\n",
    "\n",
    "    resume = trainer_config.get('resume', None)\n",
    "    pre_trained = trainer_config.get('pre_trained', None)\n",
    "\n",
    "    return UNet3DTrainer(model, optimizer, lr_scheduler, loss_criterion, eval_criterion,\n",
    "                         config['device'], loaders, trainer_config['checkpoint_dir'],\n",
    "                         max_num_epochs=trainer_config['epochs'],\n",
    "                         max_num_iterations=trainer_config['iters'],\n",
    "                         validate_after_iters=trainer_config['validate_after_iters'],\n",
    "                         log_after_iters=trainer_config['log_after_iters'],\n",
    "                         eval_score_higher_is_better=trainer_config['eval_score_higher_is_better'],\n",
    "                         logger=logger)\n",
    "\n",
    "\n",
    "def _create_optimizer(config, model):\n",
    "    assert 'optimizer' in config, 'Cannot find optimizer configuration'\n",
    "    optimizer_config = config['optimizer']\n",
    "    learning_rate = optimizer_config['learning_rate']\n",
    "    weight_decay = optimizer_config['weight_decay']\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def _create_lr_scheduler(config, optimizer):\n",
    "    lr_config = config.get('lr_scheduler', None)\n",
    "    if lr_config is None:\n",
    "        # use ReduceLROnPlateau as a default scheduler\n",
    "        return ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=20, verbose=True)\n",
    "    else:\n",
    "        class_name = lr_config.pop('name')\n",
    "        m = importlib.import_module('torch.optim.lr_scheduler')\n",
    "        clazz = getattr(m, class_name)\n",
    "        # add optimizer to the config\n",
    "        lr_config['optimizer'] = optimizer\n",
    "        return clazz(**lr_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-12 09:54:03,186 [MainThread] INFO UNet3DTrainer - Seed the RNG for all devices with 0\n",
      "2019-07-12 09:54:03,186 [MainThread] INFO UNet3DTrainer - Seed the RNG for all devices with 0\n",
      "2019-07-12 09:54:03,186 [MainThread] INFO UNet3DTrainer - Seed the RNG for all devices with 0\n",
      "2019-07-12 09:54:03,238 [MainThread] INFO UNet3DTrainer - Sending the model to 'cpu'\n",
      "2019-07-12 09:54:03,238 [MainThread] INFO UNet3DTrainer - Sending the model to 'cpu'\n",
      "2019-07-12 09:54:03,238 [MainThread] INFO UNet3DTrainer - Sending the model to 'cpu'\n",
      "2019-07-12 09:54:03,241 [MainThread] INFO UNet3DTrainer - Number of learnable params 4080881\n",
      "2019-07-12 09:54:03,241 [MainThread] INFO UNet3DTrainer - Number of learnable params 4080881\n",
      "2019-07-12 09:54:03,241 [MainThread] INFO UNet3DTrainer - Number of learnable params 4080881\n",
      "2019-07-12 09:54:03,243 [MainThread] INFO HDF5Dataset - Creating training and validation set loaders...\n",
      "2019-07-12 09:54:03,243 [MainThread] INFO HDF5Dataset - Creating training and validation set loaders...\n",
      "2019-07-12 09:54:03,243 [MainThread] INFO HDF5Dataset - Creating training and validation set loaders...\n",
      "2019-07-12 09:54:03,246 [MainThread] INFO HDF5Dataset - Slice builder class: SliceBuilder\n",
      "2019-07-12 09:54:03,246 [MainThread] INFO HDF5Dataset - Slice builder class: SliceBuilder\n",
      "2019-07-12 09:54:03,246 [MainThread] INFO HDF5Dataset - Slice builder class: SliceBuilder\n",
      "2019-07-12 09:54:03,248 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/0.h5...\n",
      "2019-07-12 09:54:03,248 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/0.h5...\n",
      "2019-07-12 09:54:03,248 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/0.h5...\n",
      "2019-07-12 09:54:03,336 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/1.h5...\n",
      "2019-07-12 09:54:03,336 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/1.h5...\n",
      "2019-07-12 09:54:03,336 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/1.h5...\n",
      "2019-07-12 09:54:03,415 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/2.h5...\n",
      "2019-07-12 09:54:03,415 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/2.h5...\n",
      "2019-07-12 09:54:03,415 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/2.h5...\n",
      "2019-07-12 09:54:03,489 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/3.h5...\n",
      "2019-07-12 09:54:03,489 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/3.h5...\n",
      "2019-07-12 09:54:03,489 [MainThread] INFO HDF5Dataset - Loading training set from: ../suki_fractals/suki_files/h5/3.h5...\n",
      "2019-07-12 09:54:03,559 [MainThread] INFO HDF5Dataset - Loading validation set from: ../suki_fractals/suki_files/h5/4.h5...\n",
      "2019-07-12 09:54:03,559 [MainThread] INFO HDF5Dataset - Loading validation set from: ../suki_fractals/suki_files/h5/4.h5...\n",
      "2019-07-12 09:54:03,559 [MainThread] INFO HDF5Dataset - Loading validation set from: ../suki_fractals/suki_files/h5/4.h5...\n",
      "2019-07-12 09:54:03,633 [MainThread] INFO HDF5Dataset - Number of workers for train/val datasets: 8\n",
      "2019-07-12 09:54:03,633 [MainThread] INFO HDF5Dataset - Number of workers for train/val datasets: 8\n",
      "2019-07-12 09:54:03,633 [MainThread] INFO HDF5Dataset - Number of workers for train/val datasets: 8\n",
      "2019-07-12 09:54:03,636 [MainThread] INFO UNet3DTrainer - UNet3D(\n",
      "  (encoders): ModuleList(\n",
      "    (0): Encoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (final_activation): Sigmoid()\n",
      ")\n",
      "2019-07-12 09:54:03,636 [MainThread] INFO UNet3DTrainer - UNet3D(\n",
      "  (encoders): ModuleList(\n",
      "    (0): Encoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (final_activation): Sigmoid()\n",
      ")\n",
      "2019-07-12 09:54:03,636 [MainThread] INFO UNet3DTrainer - UNet3D(\n",
      "  (encoders): ModuleList(\n",
      "    (0): Encoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Encoder(\n",
      "      (pooling): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoders): ModuleList(\n",
      "    (0): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Decoder(\n",
      "      (basic_module): DoubleConv(\n",
      "        (SingleConv1): SingleConv(\n",
      "          (conv): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (SingleConv2): SingleConv(\n",
      "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "          (ReLU): ReLU(inplace)\n",
      "          (groupnorm): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (final_activation): Sigmoid()\n",
      ")\n",
      "2019-07-12 09:54:03,644 [MainThread] INFO UNet3DTrainer - eval_score_higher_is_better: True\n",
      "2019-07-12 09:54:03,644 [MainThread] INFO UNet3DTrainer - eval_score_higher_is_better: True\n",
      "2019-07-12 09:54:03,644 [MainThread] INFO UNet3DTrainer - eval_score_higher_is_better: True\n",
      "2019-07-12 09:54:04,098 [MainThread] INFO UNet3DTrainer - Training iteration 1. Batch 0. Epoch [0/49]\n",
      "2019-07-12 09:54:04,098 [MainThread] INFO UNet3DTrainer - Training iteration 1. Batch 0. Epoch [0/49]\n",
      "2019-07-12 09:54:04,098 [MainThread] INFO UNet3DTrainer - Training iteration 1. Batch 0. Epoch [0/49]\n",
      "2019-07-12 09:54:12,482 [MainThread] INFO UNet3DTrainer - Training iteration 2. Batch 1. Epoch [0/49]\n",
      "2019-07-12 09:54:12,482 [MainThread] INFO UNet3DTrainer - Training iteration 2. Batch 1. Epoch [0/49]\n",
      "2019-07-12 09:54:12,482 [MainThread] INFO UNet3DTrainer - Training iteration 2. Batch 1. Epoch [0/49]\n",
      "2019-07-12 09:54:18,836 [MainThread] INFO UNet3DTrainer - Training iteration 3. Batch 2. Epoch [0/49]\n",
      "2019-07-12 09:54:18,836 [MainThread] INFO UNet3DTrainer - Training iteration 3. Batch 2. Epoch [0/49]\n",
      "2019-07-12 09:54:18,836 [MainThread] INFO UNet3DTrainer - Training iteration 3. Batch 2. Epoch [0/49]\n",
      "2019-07-12 09:54:24,647 [MainThread] INFO UNet3DTrainer - Training iteration 4. Batch 3. Epoch [0/49]\n",
      "2019-07-12 09:54:24,647 [MainThread] INFO UNet3DTrainer - Training iteration 4. Batch 3. Epoch [0/49]\n",
      "2019-07-12 09:54:24,647 [MainThread] INFO UNet3DTrainer - Training iteration 4. Batch 3. Epoch [0/49]\n",
      "2019-07-12 09:54:30,428 [MainThread] INFO UNet3DTrainer - Training iteration 5. Batch 4. Epoch [0/49]\n",
      "2019-07-12 09:54:30,428 [MainThread] INFO UNet3DTrainer - Training iteration 5. Batch 4. Epoch [0/49]\n",
      "2019-07-12 09:54:30,428 [MainThread] INFO UNet3DTrainer - Training iteration 5. Batch 4. Epoch [0/49]\n",
      "2019-07-12 09:54:36,170 [MainThread] INFO UNet3DTrainer - Training iteration 6. Batch 5. Epoch [0/49]\n",
      "2019-07-12 09:54:36,170 [MainThread] INFO UNet3DTrainer - Training iteration 6. Batch 5. Epoch [0/49]\n",
      "2019-07-12 09:54:36,170 [MainThread] INFO UNet3DTrainer - Training iteration 6. Batch 5. Epoch [0/49]\n",
      "2019-07-12 09:54:41,888 [MainThread] INFO UNet3DTrainer - Training iteration 7. Batch 6. Epoch [0/49]\n",
      "2019-07-12 09:54:41,888 [MainThread] INFO UNet3DTrainer - Training iteration 7. Batch 6. Epoch [0/49]\n",
      "2019-07-12 09:54:41,888 [MainThread] INFO UNet3DTrainer - Training iteration 7. Batch 6. Epoch [0/49]\n",
      "2019-07-12 09:54:47,778 [MainThread] INFO UNet3DTrainer - Training iteration 8. Batch 7. Epoch [0/49]\n",
      "2019-07-12 09:54:47,778 [MainThread] INFO UNet3DTrainer - Training iteration 8. Batch 7. Epoch [0/49]\n",
      "2019-07-12 09:54:47,778 [MainThread] INFO UNet3DTrainer - Training iteration 8. Batch 7. Epoch [0/49]\n",
      "2019-07-12 09:54:53,908 [MainThread] INFO UNet3DTrainer - Training iteration 9. Batch 8. Epoch [0/49]\n",
      "2019-07-12 09:54:53,908 [MainThread] INFO UNet3DTrainer - Training iteration 9. Batch 8. Epoch [0/49]\n",
      "2019-07-12 09:54:53,908 [MainThread] INFO UNet3DTrainer - Training iteration 9. Batch 8. Epoch [0/49]\n",
      "2019-07-12 09:54:59,626 [MainThread] INFO UNet3DTrainer - Training iteration 10. Batch 9. Epoch [0/49]\n",
      "2019-07-12 09:54:59,626 [MainThread] INFO UNet3DTrainer - Training iteration 10. Batch 9. Epoch [0/49]\n",
      "2019-07-12 09:54:59,626 [MainThread] INFO UNet3DTrainer - Training iteration 10. Batch 9. Epoch [0/49]\n",
      "2019-07-12 09:55:05,443 [MainThread] INFO UNet3DTrainer - Training iteration 11. Batch 10. Epoch [0/49]\n",
      "2019-07-12 09:55:05,443 [MainThread] INFO UNet3DTrainer - Training iteration 11. Batch 10. Epoch [0/49]\n",
      "2019-07-12 09:55:05,443 [MainThread] INFO UNet3DTrainer - Training iteration 11. Batch 10. Epoch [0/49]\n",
      "2019-07-12 09:55:11,205 [MainThread] INFO UNet3DTrainer - Training iteration 12. Batch 11. Epoch [0/49]\n",
      "2019-07-12 09:55:11,205 [MainThread] INFO UNet3DTrainer - Training iteration 12. Batch 11. Epoch [0/49]\n",
      "2019-07-12 09:55:11,205 [MainThread] INFO UNet3DTrainer - Training iteration 12. Batch 11. Epoch [0/49]\n",
      "2019-07-12 09:55:17,031 [MainThread] INFO UNet3DTrainer - Training iteration 13. Batch 12. Epoch [0/49]\n",
      "2019-07-12 09:55:17,031 [MainThread] INFO UNet3DTrainer - Training iteration 13. Batch 12. Epoch [0/49]\n",
      "2019-07-12 09:55:17,031 [MainThread] INFO UNet3DTrainer - Training iteration 13. Batch 12. Epoch [0/49]\n",
      "2019-07-12 09:55:23,170 [MainThread] INFO UNet3DTrainer - Training iteration 14. Batch 13. Epoch [0/49]\n",
      "2019-07-12 09:55:23,170 [MainThread] INFO UNet3DTrainer - Training iteration 14. Batch 13. Epoch [0/49]\n",
      "2019-07-12 09:55:23,170 [MainThread] INFO UNet3DTrainer - Training iteration 14. Batch 13. Epoch [0/49]\n",
      "2019-07-12 09:55:29,096 [MainThread] INFO UNet3DTrainer - Training iteration 15. Batch 14. Epoch [0/49]\n",
      "2019-07-12 09:55:29,096 [MainThread] INFO UNet3DTrainer - Training iteration 15. Batch 14. Epoch [0/49]\n",
      "2019-07-12 09:55:29,096 [MainThread] INFO UNet3DTrainer - Training iteration 15. Batch 14. Epoch [0/49]\n",
      "2019-07-12 09:55:35,211 [MainThread] INFO UNet3DTrainer - Training iteration 16. Batch 15. Epoch [0/49]\n",
      "2019-07-12 09:55:35,211 [MainThread] INFO UNet3DTrainer - Training iteration 16. Batch 15. Epoch [0/49]\n",
      "2019-07-12 09:55:35,211 [MainThread] INFO UNet3DTrainer - Training iteration 16. Batch 15. Epoch [0/49]\n",
      "2019-07-12 09:55:41,181 [MainThread] INFO UNet3DTrainer - Training iteration 17. Batch 16. Epoch [0/49]\n",
      "2019-07-12 09:55:41,181 [MainThread] INFO UNet3DTrainer - Training iteration 17. Batch 16. Epoch [0/49]\n",
      "2019-07-12 09:55:41,181 [MainThread] INFO UNet3DTrainer - Training iteration 17. Batch 16. Epoch [0/49]\n",
      "2019-07-12 09:55:47,081 [MainThread] INFO UNet3DTrainer - Training iteration 18. Batch 17. Epoch [0/49]\n",
      "2019-07-12 09:55:47,081 [MainThread] INFO UNet3DTrainer - Training iteration 18. Batch 17. Epoch [0/49]\n",
      "2019-07-12 09:55:47,081 [MainThread] INFO UNet3DTrainer - Training iteration 18. Batch 17. Epoch [0/49]\n",
      "2019-07-12 09:55:53,020 [MainThread] INFO UNet3DTrainer - Training iteration 19. Batch 18. Epoch [0/49]\n",
      "2019-07-12 09:55:53,020 [MainThread] INFO UNet3DTrainer - Training iteration 19. Batch 18. Epoch [0/49]\n",
      "2019-07-12 09:55:53,020 [MainThread] INFO UNet3DTrainer - Training iteration 19. Batch 18. Epoch [0/49]\n",
      "2019-07-12 09:55:58,916 [MainThread] INFO UNet3DTrainer - Training iteration 20. Batch 19. Epoch [0/49]\n",
      "2019-07-12 09:55:58,916 [MainThread] INFO UNet3DTrainer - Training iteration 20. Batch 19. Epoch [0/49]\n",
      "2019-07-12 09:55:58,916 [MainThread] INFO UNet3DTrainer - Training iteration 20. Batch 19. Epoch [0/49]\n",
      "2019-07-12 09:56:04,820 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-12 09:56:04,820 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-12 09:56:04,820 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-12 09:56:04,950 [MainThread] INFO UNet3DTrainer - Validation iteration 0\n",
      "2019-07-12 09:56:04,950 [MainThread] INFO UNet3DTrainer - Validation iteration 0\n",
      "2019-07-12 09:56:04,950 [MainThread] INFO UNet3DTrainer - Validation iteration 0\n",
      "2019-07-12 09:56:07,430 [MainThread] INFO UNet3DTrainer - Validation iteration 1\n",
      "2019-07-12 09:56:07,430 [MainThread] INFO UNet3DTrainer - Validation iteration 1\n",
      "2019-07-12 09:56:07,430 [MainThread] INFO UNet3DTrainer - Validation iteration 1\n",
      "2019-07-12 09:56:09,904 [MainThread] INFO UNet3DTrainer - Validation iteration 2\n",
      "2019-07-12 09:56:09,904 [MainThread] INFO UNet3DTrainer - Validation iteration 2\n",
      "2019-07-12 09:56:09,904 [MainThread] INFO UNet3DTrainer - Validation iteration 2\n",
      "2019-07-12 09:56:12,408 [MainThread] INFO UNet3DTrainer - Validation iteration 3\n",
      "2019-07-12 09:56:12,408 [MainThread] INFO UNet3DTrainer - Validation iteration 3\n",
      "2019-07-12 09:56:12,408 [MainThread] INFO UNet3DTrainer - Validation iteration 3\n",
      "2019-07-12 09:56:14,903 [MainThread] INFO UNet3DTrainer - Validation iteration 4\n",
      "2019-07-12 09:56:14,903 [MainThread] INFO UNet3DTrainer - Validation iteration 4\n",
      "2019-07-12 09:56:14,903 [MainThread] INFO UNet3DTrainer - Validation iteration 4\n",
      "2019-07-12 09:56:17,399 [MainThread] INFO UNet3DTrainer - Validation iteration 5\n",
      "2019-07-12 09:56:17,399 [MainThread] INFO UNet3DTrainer - Validation iteration 5\n",
      "2019-07-12 09:56:17,399 [MainThread] INFO UNet3DTrainer - Validation iteration 5\n",
      "2019-07-12 09:56:19,902 [MainThread] INFO UNet3DTrainer - Validation iteration 6\n",
      "2019-07-12 09:56:19,902 [MainThread] INFO UNet3DTrainer - Validation iteration 6\n",
      "2019-07-12 09:56:19,902 [MainThread] INFO UNet3DTrainer - Validation iteration 6\n",
      "2019-07-12 09:56:22,601 [MainThread] INFO UNet3DTrainer - Validation iteration 7\n",
      "2019-07-12 09:56:22,601 [MainThread] INFO UNet3DTrainer - Validation iteration 7\n",
      "2019-07-12 09:56:22,601 [MainThread] INFO UNet3DTrainer - Validation iteration 7\n",
      "2019-07-12 09:56:25,125 [MainThread] INFO UNet3DTrainer - Validation iteration 8\n",
      "2019-07-12 09:56:25,125 [MainThread] INFO UNet3DTrainer - Validation iteration 8\n",
      "2019-07-12 09:56:25,125 [MainThread] INFO UNet3DTrainer - Validation iteration 8\n",
      "2019-07-12 09:56:27,753 [MainThread] INFO UNet3DTrainer - Validation iteration 9\n",
      "2019-07-12 09:56:27,753 [MainThread] INFO UNet3DTrainer - Validation iteration 9\n",
      "2019-07-12 09:56:27,753 [MainThread] INFO UNet3DTrainer - Validation iteration 9\n",
      "2019-07-12 09:56:30,277 [MainThread] INFO UNet3DTrainer - Validation iteration 10\n",
      "2019-07-12 09:56:30,277 [MainThread] INFO UNet3DTrainer - Validation iteration 10\n",
      "2019-07-12 09:56:30,277 [MainThread] INFO UNet3DTrainer - Validation iteration 10\n",
      "2019-07-12 09:56:32,775 [MainThread] INFO UNet3DTrainer - Validation iteration 11\n",
      "2019-07-12 09:56:32,775 [MainThread] INFO UNet3DTrainer - Validation iteration 11\n",
      "2019-07-12 09:56:32,775 [MainThread] INFO UNet3DTrainer - Validation iteration 11\n",
      "2019-07-12 09:56:35,284 [MainThread] INFO UNet3DTrainer - Validation iteration 12\n",
      "2019-07-12 09:56:35,284 [MainThread] INFO UNet3DTrainer - Validation iteration 12\n",
      "2019-07-12 09:56:35,284 [MainThread] INFO UNet3DTrainer - Validation iteration 12\n",
      "2019-07-12 09:56:37,759 [MainThread] INFO UNet3DTrainer - Validation iteration 13\n",
      "2019-07-12 09:56:37,759 [MainThread] INFO UNet3DTrainer - Validation iteration 13\n",
      "2019-07-12 09:56:37,759 [MainThread] INFO UNet3DTrainer - Validation iteration 13\n",
      "2019-07-12 09:56:40,295 [MainThread] INFO UNet3DTrainer - Validation iteration 14\n",
      "2019-07-12 09:56:40,295 [MainThread] INFO UNet3DTrainer - Validation iteration 14\n",
      "2019-07-12 09:56:40,295 [MainThread] INFO UNet3DTrainer - Validation iteration 14\n",
      "2019-07-12 09:56:42,800 [MainThread] INFO UNet3DTrainer - Validation iteration 15\n",
      "2019-07-12 09:56:42,800 [MainThread] INFO UNet3DTrainer - Validation iteration 15\n",
      "2019-07-12 09:56:42,800 [MainThread] INFO UNet3DTrainer - Validation iteration 15\n",
      "2019-07-12 09:56:45,460 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.9999892674386501. Evaluation score: 1.5130241081351414e-05\n",
      "2019-07-12 09:56:45,460 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.9999892674386501. Evaluation score: 1.5130241081351414e-05\n",
      "2019-07-12 09:56:45,460 [MainThread] INFO UNet3DTrainer - Validation finished. Loss: 0.9999892674386501. Evaluation score: 1.5130241081351414e-05\n",
      "2019-07-12 09:56:45,464 [MainThread] INFO UNet3DTrainer - Saving new best evaluation metric: 1.5130241081351414e-05\n",
      "2019-07-12 09:56:45,464 [MainThread] INFO UNet3DTrainer - Saving new best evaluation metric: 1.5130241081351414e-05\n",
      "2019-07-12 09:56:45,464 [MainThread] INFO UNet3DTrainer - Saving new best evaluation metric: 1.5130241081351414e-05\n",
      "2019-07-12 09:56:45,469 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-12 09:56:45,469 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-12 09:56:45,469 [MainThread] INFO UNet3DTrainer - Saving last checkpoint to '3dunet/last_checkpoint.pytorch'\n",
      "2019-07-12 09:56:45,505 [MainThread] INFO UNet3DTrainer - Saving best checkpoint to '3dunet/best_checkpoint.pytorch'\n",
      "2019-07-12 09:56:45,505 [MainThread] INFO UNet3DTrainer - Saving best checkpoint to '3dunet/best_checkpoint.pytorch'\n",
      "2019-07-12 09:56:45,505 [MainThread] INFO UNet3DTrainer - Saving best checkpoint to '3dunet/best_checkpoint.pytorch'\n",
      "2019-07-12 09:56:45,622 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.999955615401268. Evaluation score: 0.0\n",
      "2019-07-12 09:56:45,622 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.999955615401268. Evaluation score: 0.0\n",
      "2019-07-12 09:56:45,622 [MainThread] INFO UNet3DTrainer - Training stats. Loss: 0.999955615401268. Evaluation score: 0.0\n",
      "2019-07-12 09:56:45,626 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "2019-07-12 09:56:45,626 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "2019-07-12 09:56:45,626 [MainThread] INFO UNet3DTrainer - Logging model parameters and gradients\n",
      "Warning: NaN or Inf found in input tensor.\n",
      "2019-07-12 09:56:46,428 [MainThread] INFO UNet3DTrainer - Training iteration 21. Batch 20. Epoch [0/49]\n",
      "2019-07-12 09:56:46,428 [MainThread] INFO UNet3DTrainer - Training iteration 21. Batch 20. Epoch [0/49]\n",
      "2019-07-12 09:56:46,428 [MainThread] INFO UNet3DTrainer - Training iteration 21. Batch 20. Epoch [0/49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gheimber/Desktop/Projects/lungs/lung/pytorch-3dunet/unet3d/trainer.py:366: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (img - np.min(img)) / np.ptp(img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-12 09:56:52,852 [MainThread] INFO UNet3DTrainer - Training iteration 22. Batch 21. Epoch [0/49]\n",
      "2019-07-12 09:56:52,852 [MainThread] INFO UNet3DTrainer - Training iteration 22. Batch 21. Epoch [0/49]\n",
      "2019-07-12 09:56:52,852 [MainThread] INFO UNet3DTrainer - Training iteration 22. Batch 21. Epoch [0/49]\n",
      "2019-07-12 09:56:58,850 [MainThread] INFO UNet3DTrainer - Training iteration 23. Batch 22. Epoch [0/49]\n",
      "2019-07-12 09:56:58,850 [MainThread] INFO UNet3DTrainer - Training iteration 23. Batch 22. Epoch [0/49]\n",
      "2019-07-12 09:56:58,850 [MainThread] INFO UNet3DTrainer - Training iteration 23. Batch 22. Epoch [0/49]\n",
      "2019-07-12 09:57:04,906 [MainThread] INFO UNet3DTrainer - Training iteration 24. Batch 23. Epoch [0/49]\n",
      "2019-07-12 09:57:04,906 [MainThread] INFO UNet3DTrainer - Training iteration 24. Batch 23. Epoch [0/49]\n",
      "2019-07-12 09:57:04,906 [MainThread] INFO UNet3DTrainer - Training iteration 24. Batch 23. Epoch [0/49]\n",
      "2019-07-12 09:57:11,159 [MainThread] INFO UNet3DTrainer - Training iteration 25. Batch 24. Epoch [0/49]\n",
      "2019-07-12 09:57:11,159 [MainThread] INFO UNet3DTrainer - Training iteration 25. Batch 24. Epoch [0/49]\n",
      "2019-07-12 09:57:11,159 [MainThread] INFO UNet3DTrainer - Training iteration 25. Batch 24. Epoch [0/49]\n",
      "2019-07-12 09:57:17,263 [MainThread] INFO UNet3DTrainer - Training iteration 26. Batch 25. Epoch [0/49]\n",
      "2019-07-12 09:57:17,263 [MainThread] INFO UNet3DTrainer - Training iteration 26. Batch 25. Epoch [0/49]\n",
      "2019-07-12 09:57:17,263 [MainThread] INFO UNet3DTrainer - Training iteration 26. Batch 25. Epoch [0/49]\n",
      "2019-07-12 09:57:23,605 [MainThread] INFO UNet3DTrainer - Training iteration 27. Batch 26. Epoch [0/49]\n",
      "2019-07-12 09:57:23,605 [MainThread] INFO UNet3DTrainer - Training iteration 27. Batch 26. Epoch [0/49]\n",
      "2019-07-12 09:57:23,605 [MainThread] INFO UNet3DTrainer - Training iteration 27. Batch 26. Epoch [0/49]\n",
      "2019-07-12 09:57:30,673 [MainThread] INFO UNet3DTrainer - Training iteration 28. Batch 27. Epoch [0/49]\n",
      "2019-07-12 09:57:30,673 [MainThread] INFO UNet3DTrainer - Training iteration 28. Batch 27. Epoch [0/49]\n",
      "2019-07-12 09:57:30,673 [MainThread] INFO UNet3DTrainer - Training iteration 28. Batch 27. Epoch [0/49]\n",
      "2019-07-12 09:57:36,926 [MainThread] INFO UNet3DTrainer - Training iteration 29. Batch 28. Epoch [0/49]\n",
      "2019-07-12 09:57:36,926 [MainThread] INFO UNet3DTrainer - Training iteration 29. Batch 28. Epoch [0/49]\n",
      "2019-07-12 09:57:36,926 [MainThread] INFO UNet3DTrainer - Training iteration 29. Batch 28. Epoch [0/49]\n",
      "2019-07-12 09:57:43,196 [MainThread] INFO UNet3DTrainer - Training iteration 30. Batch 29. Epoch [0/49]\n",
      "2019-07-12 09:57:43,196 [MainThread] INFO UNet3DTrainer - Training iteration 30. Batch 29. Epoch [0/49]\n",
      "2019-07-12 09:57:43,196 [MainThread] INFO UNet3DTrainer - Training iteration 30. Batch 29. Epoch [0/49]\n",
      "2019-07-12 09:57:49,442 [MainThread] INFO UNet3DTrainer - Training iteration 31. Batch 30. Epoch [0/49]\n",
      "2019-07-12 09:57:49,442 [MainThread] INFO UNet3DTrainer - Training iteration 31. Batch 30. Epoch [0/49]\n",
      "2019-07-12 09:57:49,442 [MainThread] INFO UNet3DTrainer - Training iteration 31. Batch 30. Epoch [0/49]\n",
      "2019-07-12 09:57:56,978 [MainThread] INFO UNet3DTrainer - Training iteration 32. Batch 31. Epoch [0/49]\n",
      "2019-07-12 09:57:56,978 [MainThread] INFO UNet3DTrainer - Training iteration 32. Batch 31. Epoch [0/49]\n",
      "2019-07-12 09:57:56,978 [MainThread] INFO UNet3DTrainer - Training iteration 32. Batch 31. Epoch [0/49]\n",
      "2019-07-12 09:58:04,054 [MainThread] INFO UNet3DTrainer - Training iteration 33. Batch 32. Epoch [0/49]\n",
      "2019-07-12 09:58:04,054 [MainThread] INFO UNet3DTrainer - Training iteration 33. Batch 32. Epoch [0/49]\n",
      "2019-07-12 09:58:04,054 [MainThread] INFO UNet3DTrainer - Training iteration 33. Batch 32. Epoch [0/49]\n",
      "2019-07-12 09:58:11,245 [MainThread] INFO UNet3DTrainer - Training iteration 34. Batch 33. Epoch [0/49]\n",
      "2019-07-12 09:58:11,245 [MainThread] INFO UNet3DTrainer - Training iteration 34. Batch 33. Epoch [0/49]\n",
      "2019-07-12 09:58:11,245 [MainThread] INFO UNet3DTrainer - Training iteration 34. Batch 33. Epoch [0/49]\n",
      "2019-07-12 09:58:21,070 [MainThread] INFO UNet3DTrainer - Training iteration 35. Batch 34. Epoch [0/49]\n",
      "2019-07-12 09:58:21,070 [MainThread] INFO UNet3DTrainer - Training iteration 35. Batch 34. Epoch [0/49]\n",
      "2019-07-12 09:58:21,070 [MainThread] INFO UNet3DTrainer - Training iteration 35. Batch 34. Epoch [0/49]\n",
      "2019-07-12 09:58:27,628 [MainThread] INFO UNet3DTrainer - Training iteration 36. Batch 35. Epoch [0/49]\n",
      "2019-07-12 09:58:27,628 [MainThread] INFO UNet3DTrainer - Training iteration 36. Batch 35. Epoch [0/49]\n",
      "2019-07-12 09:58:27,628 [MainThread] INFO UNet3DTrainer - Training iteration 36. Batch 35. Epoch [0/49]\n",
      "2019-07-12 09:58:34,394 [MainThread] INFO UNet3DTrainer - Training iteration 37. Batch 36. Epoch [0/49]\n",
      "2019-07-12 09:58:34,394 [MainThread] INFO UNet3DTrainer - Training iteration 37. Batch 36. Epoch [0/49]\n",
      "2019-07-12 09:58:34,394 [MainThread] INFO UNet3DTrainer - Training iteration 37. Batch 36. Epoch [0/49]\n",
      "2019-07-12 09:58:41,538 [MainThread] INFO UNet3DTrainer - Training iteration 38. Batch 37. Epoch [0/49]\n",
      "2019-07-12 09:58:41,538 [MainThread] INFO UNet3DTrainer - Training iteration 38. Batch 37. Epoch [0/49]\n",
      "2019-07-12 09:58:41,538 [MainThread] INFO UNet3DTrainer - Training iteration 38. Batch 37. Epoch [0/49]\n",
      "2019-07-12 09:58:49,484 [MainThread] INFO UNet3DTrainer - Training iteration 39. Batch 38. Epoch [0/49]\n",
      "2019-07-12 09:58:49,484 [MainThread] INFO UNet3DTrainer - Training iteration 39. Batch 38. Epoch [0/49]\n",
      "2019-07-12 09:58:49,484 [MainThread] INFO UNet3DTrainer - Training iteration 39. Batch 38. Epoch [0/49]\n",
      "2019-07-12 09:58:56,667 [MainThread] INFO UNet3DTrainer - Training iteration 40. Batch 39. Epoch [0/49]\n",
      "2019-07-12 09:58:56,667 [MainThread] INFO UNet3DTrainer - Training iteration 40. Batch 39. Epoch [0/49]\n",
      "2019-07-12 09:58:56,667 [MainThread] INFO UNet3DTrainer - Training iteration 40. Batch 39. Epoch [0/49]\n",
      "2019-07-12 09:59:03,274 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-12 09:59:03,274 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-12 09:59:03,274 [MainThread] INFO UNet3DTrainer - Validating...\n",
      "2019-07-12 09:59:03,358 [MainThread] INFO UNet3DTrainer - Validation iteration 0\n",
      "2019-07-12 09:59:03,358 [MainThread] INFO UNet3DTrainer - Validation iteration 0\n",
      "2019-07-12 09:59:03,358 [MainThread] INFO UNet3DTrainer - Validation iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/anaconda3/envs/lung/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and log experiment configuration\n",
    "manual_seed = config.get('manual_seed', None)\n",
    "if manual_seed is not None:\n",
    "    logger.info(f'Seed the RNG for all devices with {manual_seed}')\n",
    "    torch.manual_seed(manual_seed)\n",
    "    # see https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Create the model\n",
    "model = get_model(config)\n",
    "\n",
    "# put the model on GPUs (if available)\n",
    "#if torch.cuda.is_available():\n",
    "logger.info(f\"Sending the model to '{config['device']}'\")\n",
    "model = model.to(config['device'])\n",
    "                \n",
    "# Log the number of learnable parameters\n",
    "logger.info(f'Number of learnable params {get_number_of_learnable_parameters(model)}')\n",
    "\n",
    "# Create loss criterion\n",
    "loss_criterion = get_loss_criterion(config)\n",
    "# Create evaluation metric\n",
    "eval_criterion = get_evaluation_metric(config)\n",
    "\n",
    "# Create data loaders\n",
    "loaders = get_train_loaders(config)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = _create_optimizer(config, model)\n",
    "\n",
    "# Create learning rate adjustment strategy\n",
    "lr_scheduler = _create_lr_scheduler(config, optimizer)\n",
    "\n",
    "# Create model trainer\n",
    "trainer = _create_trainer(config, model=model, optimizer=optimizer, lr_scheduler=lr_scheduler,\n",
    "                          loss_criterion=loss_criterion, eval_criterion=eval_criterion, loaders=loaders,\n",
    "                          logger=logger)\n",
    "# Start training\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung",
   "language": "python",
   "name": "lung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
